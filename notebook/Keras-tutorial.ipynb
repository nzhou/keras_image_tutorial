{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Welcome to the Image Transfer Learning tutorial!</b>\n",
    "\n",
    "Today you will try out one of the most cutting-edge image recognition models in the industry and train some of your own as well. \n",
    "\n",
    "This tutorial is adapted from the examples at https://keras.io/applications/. You can find out more after the session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not using the docker image we provide, let's first install the packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Keras with the Tensforflow backend to train the models. \n",
    "# If pip doesn't work well for you, please install Anaconda and use conda to install tensorflow instead.\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {
    "directory.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from http://download.tensorflow.org/example_images/flower_photos.tgz with the following command: <br>\n",
    "`curl -LO http://download.tensorflow.org/example_images/flower_photos.tgz` <br>\n",
    "And then, please decompress it to the path `data/flower_photos/train`. Note that this will take a while. If you use the docker image we provide, the data should have already been downloaded and extracted for you. Please go to `data/flower_photos/train` to make sure the data is organized correctly like the following, each class with its own subcategory. :\n",
    "![directory.png](attachment:directory.png)\n",
    "In the 'data/flower_photos/train' folder, you can put any images you like to test the models you will train today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the parameters for training. We have already talked about them in the presentation just now. Do you recognize them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images. \n",
    "img_width, img_height = 224, 224 \n",
    "# If you put the ta in a different path from what is shown above, you should change the path here as well.\n",
    "train_data_dir = '../data/flower_photos/train' \n",
    "epochs = 5 # about 3-5 min per epoch on cpu without multi-threading\n",
    "batch_size = 32\n",
    "steps_per_epoch = 25\n",
    "val_step = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the results easier to read, we provide a helper function to map the scores to the class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['rose', 'tulip', 'daisy', 'dandelion', 'sunflower']\n",
    "class_names = sorted(class_names) # Sorting them\n",
    "\n",
    "def prob_to_class(class_names, probs):\n",
    "    return dict(zip(class_names, probs.ravel().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise 1: Play with the original Inception v3 model from Google </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the full InceptionV3 model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "model = InceptionV3(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a helper function to make it easier to test on one image. Can you tell what the function does before calling `model.predict()` to calculate the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on one image\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "def test_one_image(img_path, target_w, target_h, model):\n",
    "    img = image.load_img(img_path, target_size=(target_w, target_h))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model on a daisy image we found on the Internet. It worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "test_image = '../data/flower_photos/test/1.jpg'\n",
    "imshow(imread(test_image))\n",
    "result = test_one_image(test_image, img_width, img_height, model)\n",
    "print('Predicted:', decode_predictions(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn! Test an image you select with the model to see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise 2: Use transfer learning to retrain the model for flowers</b>\n",
    "\n",
    "You probably have noticed that the Inception model covers many different classes, but it doesn't include many detailed classes about flowers. This is because it is trained with the ImageNet data, which consists of over 14 million images in 21841 classes. It also includes 462 classes of different flowers, but the accuracy is not always that great. Now we will use the data we downloaded to see if we can train a different model with transfer learning to achieve a better accuracy on the 5 types of flowers that we are particularly interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = InceptionV3(include_top=False, weights='imagenet')\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 5 classes\n",
    "predictions = Dense(5, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and validation dataset\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function = preprocess_input, validation_split = 0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,  # this is where the data is\n",
    "    target_size=(img_width, img_height),  # all images will be resized\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,  # this is where the data is\n",
    "    target_size=(img_width, img_height),  # all images will be resized\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras import metrics\n",
    "\n",
    "new_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "new_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', \n",
    "                  metrics=[metrics.mae, metrics.categorical_accuracy])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=0, mode='auto'), \n",
    "             TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)]\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "history = new_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs, \n",
    "                                  callbacks=callbacks, verbose=1,\n",
    "                                  validation_data=val_generator, validation_steps=val_step)\n",
    "\n",
    "new_model.save_weights('first_try.h5')  # always save your weights after training or during training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training will take a while. We can use tensorboard --logdir=./logs to visualize the training process. It seems that it starts to overfit around epoch 3. We can enable early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's the time to test our model! Does it work better than the original Inception model on the flowers we are interested in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = '../data/flower_photos/test/2.jpg'\n",
    "imshow(imread(test_image))\n",
    "result = test_one_image(test_image, img_width, img_height, new_model)\n",
    "print('Predicted:', prob_to_class(class_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here to test more images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Exercise 3: Fine tue the model </b>\n",
    "\n",
    "It seems that the model doesn't perform that well. This is because we are only training the last layer. Now we will fine tune more layers to select the most suitable features for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, the top layers are well trained and we can start fine-tuning convolutional layers from inception V3. \n",
    "# We will freeze the bottom N layers and train the remaining top layers.\n",
    "\n",
    "fine_tune_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze the first 172 layers and unfreeze the rest:\n",
    "layer_split_idx = 172\n",
    "\n",
    "for layer in fine_tune_model.layers[:layer_split_idx]:\n",
    "   layer.trainable = False\n",
    "for layer in fine_tune_model.layers[layer_split_idx:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "fine_tune_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',\n",
    "                        metrics=[metrics.mae, metrics.categorical_accuracy])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks alongside the top Dense layers\n",
    "history2 = fine_tune_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs, \n",
    "                                         callbacks=callbacks, verbose=1,\n",
    "                                         validation_data=val_generator, validation_steps=val_step)\n",
    "\n",
    "fine_tune_model.save_weights('fine_tune.h5')  # save your weights after training\n",
    "\n",
    "# The training will be slower than the process one, because we train much more layers therefore much more parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history2.history['categorical_accuracy'])\n",
    "plt.plot(history2.history['val_categorical_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = '../data/flower_photos/test/2.jpg'\n",
    "imshow(imread(test_image))\n",
    "result = test_one_image(test_image, img_width, img_height, fine_tune_model)\n",
    "print('Predicted:', prob_to_class(class_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here to test more images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import print_summary\n",
    "print_summary(fine_tune_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Optional Exercise: Visualize the model</b>\n",
    "\n",
    "Using Pydot and GraphViz, we can generate an illustration of the model structure. The installation of GraphViz needs some manual set-up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pydot and graphviz for visualizing the model structure.\n",
    "!pip install pydot\n",
    "!pip install graphviz\n",
    "\n",
    "# Add the GraphViz path to the system path\n",
    "import os\n",
    "\n",
    "# This is the default path for windows. You need to change the path for Mac.\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will plot the model structure out for your reference. Isn't it a deep model?! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Optional Exercise: Train with a different dataset</b>\n",
    "\n",
    "Congratulations! You have learned how to train a deep neural network for image recognition with transfer learning. Now you can use the similar method to trian on your own dataset. Here are some open datasets available online:\n",
    "* Stanford dogs: http://vision.stanford.edu/aditya86/ImageNetDogs/\n",
    "* Lego pieces: https://www.kaggle.com/joosthazelzet/lego-brick-images\n",
    "* CIFAR-10: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "Note that different datasets may have different folder structures. You should modify the data generator accordingly (or modify how the data is stored accordingly) to make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Optional Exercise: Change the training parameters</b>\n",
    "\n",
    "Can you use different parameters to train the model, so that the result is better and/or faster? Here are some ideas:\n",
    "* how many data is reserved for validation\n",
    "* how many layers to freeze\n",
    "* a different optimizer such as RMSprop or Adam\n",
    "* different learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
